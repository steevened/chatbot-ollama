{
  "name": "chat-llm",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@ai-sdk/openai": "^1.0.17",
    "@langchain/core": "^0.3.27",
    "@langchain/ollama": "^0.1.4",
    "@modelfusion/vercel-ai": "^1.1.0",
    "ai": "^4.0.33",
    "modelfusion": "^0.137.0",
    "next": "15.1.4",
    "openai": "^4.78.1",
    "react": "^19.0.0",
    "react-dom": "^19.0.0"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.1.4",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}
